\chapter{Implementation}
\label{ch:implementation}

\section{Overview}

This chapter describes the implementation of SIREN, detailing the development approach, key technical components, and solutions to implementation challenges. The implementation followed an iterative methodology, building core functionality first and progressively adding features through successive refinements.

\section{Development Approach}

\subsection{Methodology}

Development followed an iterative approach with three-week sprints:

\textbf{Sprint 1-2:} Foundation setup including project structure, database initialization, basic API framework, and frontend scaffolding.

\textbf{Sprint 3-4:} Core functionality implementation including event ingestion API, database persistence, basic correlation engine, and initial dashboard.

\textbf{Sprint 5-6:} Advanced features including complete correlation rules, alert notifications, investigation interface, and Windows agent development.

\textbf{Sprint 7-8:} Refinement including performance optimization, security hardening, comprehensive testing, and documentation.

\subsection{Version Control}

Git version control with feature branching strategy ensured code stability:
\begin{itemize}
    \item \texttt{main} branch for production-ready code
    \item \texttt{develop} branch for integration
    \item Feature branches for specific capabilities
    \item Pull requests with code review before merging
\end{itemize}

\section{Backend Implementation}

\subsection{FastAPI Application Structure}

The backend follows modular organization:

\begin{verbatim}
backend/
├── app/
│   ├── api/          # API endpoint routers
│   ├── core/         # Configuration and security
│   ├── models/       # SQLAlchemy database models
│   ├── schemas/      # Pydantic validation schemas
│   ├── services/     # Business logic services
│   └── engine/       # Correlation engine
├── alembic/          # Database migrations
└── tests/            # Test suite
\end{verbatim}

\subsection{Event Ingestion Implementation}

Event ingestion endpoint validates and persists events:

\textbf{Validation:} Pydantic schemas enforce required fields (timestamp, source, event\_type, severity, hostname, event\_data).

\textbf{Normalization:} Event data standardized to common format regardless of source variations.

\textbf{Persistence:} Events inserted into database with transaction safety.

\textbf{Correlation Trigger:} New events trigger correlation engine evaluation asynchronously.

\subsection{Correlation Engine Implementation}

The correlation engine implements rule-based pattern matching:

\textbf{Rule Evaluation:} For each new event, retrieve applicable correlation rules from database.

\textbf{Pattern Matching:} Query events within rule timewindow matching specified pattern criteria.

\textbf{Threshold Detection:} When event count exceeds rule threshold, generate incident.

\textbf{Incident Creation:} Create incident record linking correlated events with appropriate severity and description.

\textbf{Alert Generation:} High/critical severity incidents trigger immediate alert notifications.

\subsection{Alert Service Implementation}

Multi-channel alerting supports email and webhooks:

\textbf{Email Notifications:} SMTP client sends formatted HTML emails to configured recipients containing incident summary, severity, affected hosts, and investigation link.

\textbf{Webhook Notifications:} HTTP POST requests to configured webhook URLs with JSON payload enabling integration with external systems (Slack, Teams, PagerDuty).

\textbf{Notification Queuing:} Background task queue ensures alert delivery does not block API responses.

\section{Frontend Implementation}

\subsection{React Application Structure}

Frontend organized by feature modules:

\begin{verbatim}
frontend/
├── src/
│   ├── components/   # Reusable UI components
│   ├── pages/        # Page-level components
│   ├── services/     # API client services
│   ├── hooks/        # Custom React hooks
│   ├── types/        # TypeScript type definitions
│   └── utils/        # Utility functions
└── public/           # Static assets
\end{verbatim}

\subsection{Dashboard Implementation}

Dashboard aggregates data through multiple API calls:

\textbf{Statistics Cards:} Async queries fetch total incidents, active alerts, monitored hosts counts.

\textbf{Charts:} Recharts library renders severity distribution pie chart and event timeline line graph.

\textbf{Recent Incidents Table:} Displays paginated incidents list with real-time updates via polling.

\textbf{Auto-refresh:} \texttt{useEffect} hook implements periodic dashboard refresh every 30 seconds.

\subsection{Incident Investigation Implementation}

Investigation interface provides comprehensive incident context:

\textbf{Data Loading:} Single incident API call retrieves full incident details with all correlated events.

\textbf{Event Timeline:} Events sorted chronologically and displayed with timestamps, event types, sources.

\textbf{Status Management:} Dropdown enables status transitions with PUT request to backend.

\textbf{Notes:} Text area allows analysts to document findings persisted to incident record.

\section{Windows Agent Implementation}

\subsection{Agent Architecture}

Python agent runs as Windows service monitoring security events:

\textbf{Event Monitoring:} \texttt{pywin32} library accesses Windows Event Log API subscribing to Security, System, and Application logs.

\textbf{Sysmon Integration:} Monitors Sysmon operational log (if installed) capturing detailed process creation, network connections, file modifications.

\textbf{Local Filtering:} Configurable filters discard clearly benign events reducing network traffic.

\textbf{Event Forwarding:} HTTP client sends filtered events to SIREN backend with authentication token.

\textbf{Error Handling:} Retry logic with exponential backoff handles temporary network failures.

\subsection{Agent Deployment}

Agent packaged as Windows executable via PyInstaller:
\begin{itemize}
    \item Single-file executable simplifying deployment
    \item Configuration file for SIREN server URL and authentication
    \item Installation script registers Windows service
    \item Uninstallation script cleanly removes service
\end{itemize}

\section{Database Implementation}

\subsection{Schema Creation}

SQLAlchemy models define database schema with Alembic managing migrations:

\textbf{Model Definition:} Python classes represent tables with column types, constraints, relationships.

\textbf{Migration Generation:} Alembic detects model changes generating migration scripts.

\textbf{Migration Application:} Deploy script applies migrations creating/updating schema.

\subsection{Query Optimization}

Performance optimizations ensure responsive queries:

\textbf{Indexes:} B-tree indexes on timestamp columns, hash indexes on frequently filtered fields.

\textbf{Query Optimization:} SQLAlchemy query optimization avoiding N+1 problems through joins and eager loading.

\textbf{Connection Pooling:} Database connection pool reuses connections reducing overhead.

\section{Implementation Challenges and Solutions}

\subsection{Challenge 1: Correlation Performance}

\textbf{Problem:} Initial correlation engine queried all events for each incoming event causing performance degradation under load.

\textbf{Solution:} Implemented time-window constraint in queries limiting evaluation to recent events. Added database indexes on timestamp and event\_type fields. Result: Sub-second correlation latency even with 100,000+ events.

\subsection{Challenge 2: Agent Resource Consumption}

\textbf{Problem:} Early agent implementation consumed excessive CPU monitoring high-volume event logs.

\textbf{Solution:} Implemented event batching collecting events for 5-second intervals before forwarding. Added local filtering discarding benign event types. Result: CPU usage reduced from 15\% to <5\%.

\subsection{Challenge 3: Frontend State Management}

\textbf{Problem:} Complex state dependencies between dashboard components caused re-rendering issues.

\textbf{Solution:} Introduced React Context for shared state reducing prop drilling. Implemented useMemo and useCallback hooks preventing unnecessary re-renders. Result: Smooth dashboard performance with minimal lag.

\section{Technology Stack Utilization}

\subsection{Backend Technologies}

\textbf{FastAPI:} Leveraged automatic API documentation, async request handling, dependency injection for clean architecture.

\textbf{SQLAlchemy:} ORM abstraction enabled database-agnostic code with powerful query building capabilities.

\textbf{Pydantic:} Type validation prevented invalid data entering system reducing defensive programming needs.

\subsection{Frontend Technologies}

\textbf{React:} Component-based architecture promoted code reuse and maintainability.

\textbf{TypeScript:} Static typing caught errors during development reducing runtime bugs.

\textbf{Recharts:} Declarative charting library simplified visualization implementation.

\subsection{Development Tools}

\textbf{pytest:} Backend testing framework with fixtures and parametrized tests.

\textbf{Jest/RTL:} Frontend unit and integration testing.

\textbf{Postman:} API endpoint testing and documentation.

\section{Code Quality Practices}

\subsection{Code Standards}

\textbf{Python:} PEP 8 style guide enforced via \texttt{black} formatter and \texttt{flake8} linter.

\textbf{TypeScript:} ESLint with strict rules ensuring consistent code style.

\textbf{Documentation:} Docstrings for all public functions/classes, inline comments for complex logic.

\subsection{Testing Strategy}

\textbf{Unit Tests:} Individual function/component testing with mocked dependencies.

\textbf{Integration Tests:} API endpoint tests with test database.

\textbf{End-to-End Tests:} Complete workflow tests from event ingestion to dashboard display.

\section{Summary}

This chapter detailed SIREN's implementation across backend services, frontend interface, Windows agent, and database components. Iterative development methodology enabled progressive capability additions. Key implementation challenges around correlation performance, agent resource usage, and state management were successfully resolved through optimization techniques. Consistent application of code quality practices and comprehensive testing ensured system reliability. The implementation successfully realizes the design specified in Chapter 4, delivering functional security incident management capabilities.
